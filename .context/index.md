---
module-name: "AM (AgentManager)"
description: "A centralized Multi-Agent Coordination/Planning (MCP) Server using FastAPI with SQLAlchemy ORM for persistent task orchestration and external client coordination via Docker deployment"
deployment-status: "Production Ready - Docker Deployed"
version: "1.0.0"
last-updated: "2025-10-08"
related-modules:
  - name: AgentManager Core
    path: ./agent_manager/core
  - name: FastAPI Endpoints
    path: ./agent_manager/api
  - name: SQLAlchemy ORM Layer
    path: ./agent_manager/orm.py
  - name: Database Management
    path: ./agent_manager/db.py
  - name: File Access Coordination
    path: ./agent_manager/core/file_lock.py
  - name: External Client Workers
    path: ./client_worker.py
  - name: Docker Configuration
    path: ./docker-compose.yml
  - name: Environment Configuration
    path: ./.env
architecture:
  style: "Centralized MCP Server with Client-Server Coordination via Docker Containers"
  deployment: "Docker Compose with 5 containers: server, database, cache, and 2 workers"
  components:
    - name: "FastAPI Server Container"
      description: "HTTP API server providing task submission, status reporting, and coordination endpoints for external clients (Port 8001)"
    - name: "PostgreSQL Database Container"
      description: "Persistent data storage with AsyncPG driver for TaskGraph, TaskStep, and Result persistence (Port 5433)"
    - name: "Redis Cache Container"
      description: "Optional caching layer for future performance optimization (Port 6380)"
    - name: "SQLAlchemy ORM"
      description: "Database abstraction layer with async PostgreSQL support for persistent TaskGraph and Result storage"
    - name: "AgentManager Core"
      description: "Central planning, dependency resolution, and audit orchestration logic within the server environment"
    - name: "WorkerAgent Logic"
      description: "Reasoning-Acting (RA) pattern implementation for task execution within server and external clients"
    - name: "AuditorAgent Logic" 
      description: "Quality gate implementation for server-side audit and rework coordination"
    - name: "External Client Worker Containers"
      description: "Docker containers running HTTP client scripts that poll server for tasks, execute locally with OpenAI LLM, and report results back via API"
    - name: "Database Schema"
      description: "TaskGraphORM, TaskStepORM, ResultORM, FileAccessORM models for persistent state with JSON field storage and file coordination"
    - name: "File Access Coordination"
      description: "Cross-platform file locking system preventing concurrent worker conflicts with database-tracked locks and OS-level protection"
  patterns:
    - name: "Docker Container Coordination"
      usage: "Multi-container deployment with FastAPI server coordinating external worker containers via HTTP API"
    - name: "Client-Server Task Coordination"
      usage: "External clients poll FastAPI endpoints for ready tasks and report completion via HTTP POST with Bearer token authentication"
    - name: "Database-Driven State Management"
      usage: "SQLAlchemy ORM with PostgreSQL for persistent TaskGraph lifecycle and audit trail with async operations"
    - name: "Server-Side Reasoning-Acting"
      usage: "Internal RA loops for task execution with structured ThoughtAction outputs and OpenAI LLM integration"
    - name: "HTTP API Audit Loop"
      usage: "Server-coordinated quality control with database-driven rework task updates via API endpoints"
    - name: "File Access Safety Coordination"
      usage: "Multi-level file locking with database coordination and OS-level locks preventing concurrent access conflicts"
---

# AM (AgentManager) - Centralized MCP Server

## Project Overview

AM (AgentManager) is a sophisticated **Multi-Agent Coordination/Planning (MCP) Server** built with FastAPI that orchestrates distributed task execution through HTTP API coordination via **Docker containers**. The system provides persistent task management using SQLAlchemy ORM with PostgreSQL support, enabling external client workers to coordinate through RESTful endpoints while maintaining centralized state control.

## Production Deployment Status âœ…

**FULLY DEPLOYED AND OPERATIONAL** - The AgentManager system is successfully running in Docker with:
- âœ… **5 Docker containers** actively coordinating multi-agent workflows
- âœ… **PostgreSQL database** (port 5433) with async operations
- âœ… **FastAPI server** (port 8001) handling API coordination  
- âœ… **2 Worker containers** executing tasks with OpenAI LLM integration
- âœ… **Redis cache** (port 6380) for future optimization
- âœ… **End-to-end workflow** successfully tested and verified

## MCP Server Architecture Philosophy

The system is built on seven core principles:

1. **Centralized HTTP Coordination**: FastAPI server manages all task distribution and result collection via REST endpoints
2. **Persistent ORM State Management**: SQLAlchemy models ensure durable TaskGraph storage with PostgreSQL async operations  
3. **External Client Coordination**: Worker clients poll server APIs for tasks and report results via HTTP POST
4. **Server-Side Quality Control**: Centralized audit logic with database-driven rework coordination
5. **Reasoning-Acting Integration**: RA pattern implementation both server-side and in external clients
6. **File Access Safety**: Cross-platform file locking preventing concurrent worker conflicts with database coordination
7. **Production-Ready Deployment**: Docker containerization with PostgreSQL, Redis, and multi-worker scaling

## Revolutionary MCP Workflow

The system follows a sophisticated **Docker-orchestrated** client-server coordination workflow:

1. **API Task Submission**: External clients submit complex requests via `POST /v1/tasks` with Bearer token authentication
2. **Server-Side Planning**: AgentManager creates TaskGraphs with dependencies and persists via async SQLAlchemy ORM
3. **Client Polling & Execution**: External worker containers poll for ready tasks and execute with OpenAI LLM integration
4. **Result Reporting**: Clients report completion via `POST /v1/results` with structured RAHistory data
5. **Server-Side Audit**: AuditorAgent reviews all results and triggers database-driven rework cycles
6. **Quality Loop Coordination**: Failed audits update database state to coordinate client rework
7. **Docker Coordination**: All components run in isolated containers with proper networking and resource management

## Advanced MCP Component Interaction

- **FastAPI Server Container** provides RESTful coordination endpoints for task lifecycle management (Port 8001)
- **PostgreSQL Database Container** ensures persistent state with async operations and proper data isolation (Port 5433)
- **SQLAlchemy ORM** manages TaskGraphORM, TaskStepORM, and ResultORM models with async PostgreSQL driver
- **AgentManager Core** orchestrates planning, dependency resolution, and audit coordination server-side
- **External Client Worker Containers** execute tasks with local RA loops and OpenAI LLM integration
- **Database Schema** stores complete workflow state with JSON fields for complex Pydantic data
- **LLMClient** provides structured output enforcement for both server and client agent operations
- **Docker Networking** enables secure container-to-container communication with proper service discovery

## Key MCP Server Innovations

### FastAPI REST Coordination
- `POST /v1/submit_task` - External task submission with planning trigger
- `POST /v1/report_result` - Client result reporting with audit coordination  
- `GET /v1/tasks/{role}/ready` - Client polling for available tasks
- Database session dependency injection for request handling
- API key authentication for secure client coordination

### SQLAlchemy ORM Persistence
- TaskGraphORM with JSON field storage for complex dependency graphs
- TaskStepORM with status tracking and client assignment coordination
- ResultORM with complete RAHistory storage and audit trail
- FileAccessORM with file locking coordination and conflict prevention
- Portable database configuration (SQLite development, PostgreSQL production)
- Atomic transaction management for concurrent client operations

### File Access Coordination System
- Cross-platform file locking using fcntl (Unix) and msvcrt (Windows)
- Database-tracked file access with FileAccessORM for coordination
- Task-level file dependencies declared in TaskStep models
- Automatic file path extraction and lock acquisition in WorkerAgent
- Lock compatibility matrix: read/write/exclusive access control
- Timeout handling and graceful degradation for lock conflicts

### External Client Architecture
- HTTP polling clients that coordinate task execution via API endpoints
- Local RA loop execution with server-side result reporting
- Multi-client simulation for distributed task processing
- Graceful failure handling with server-coordinated task reassignment

### Production Deployment Readiness
- PostgreSQL migration support with environment variable configuration
- Uvicorn server deployment with proper database initialization
- API security with authentication and authorization patterns
- Comprehensive logging and monitoring for production operations

## Production Deployment Guide

### Docker Deployment Status
The AgentManager system is **fully deployed and operational** using Docker Compose with the following configuration:

```yaml
# Current Production Configuration
services:
  - agent-manager:     # FastAPI Server (Port 8001)
  - postgres:          # PostgreSQL Database (Port 5433)  
  - redis:             # Redis Cache (Port 6380)
  - worker-client:     # 2 Worker Containers (scaling)
```

### Verified Production Features
- âœ… **Task Submission**: `POST /v1/tasks` with Bearer token authentication
- âœ… **Worker Polling**: `GET /v1/tasks/ready` with atomic task claiming
- âœ… **Result Reporting**: `POST /v1/results` with structured data persistence
- âœ… **Database Persistence**: PostgreSQL with async operations and migrations
- âœ… **LLM Integration**: OpenAI API working in distributed worker containers
- âœ… **Multi-Agent Coordination**: Role-based task assignment (analyst, writer, researcher)
- âœ… **Docker Networking**: Container-to-container communication with service discovery
- âœ… **Health Monitoring**: Health endpoints and container status monitoring

### Performance Metrics
- **Task Processing**: ~37 seconds per analytical task with OpenAI LLM
- **Container Resource Usage**: 4.60% CPU, 335MB memory across 5 containers
- **Database Operations**: Async PostgreSQL with connection pooling
- **API Response Time**: Sub-second for task polling and submission

## Implementation Approach

The MCP server project emphasizes:
- **API-First Design**: All coordination through RESTful HTTP endpoints with Bearer token auth
- **ORM-Based Persistence**: SQLAlchemy models with async PostgreSQL for robust database state management
- **Client-Server Separation**: Clear separation between server logic and external client execution
- **File Access Safety**: Multi-level file locking preventing concurrent worker conflicts
- **Production Readiness**: Docker deployment with PostgreSQL and Redis for scaling
- **Quality Assurance**: Server-side audit loops with database-coordinated client rework

## Getting Started

The system is **production-ready** and deployed as a centralized coordination server with external client workers. Use `docker-compose up -d` to start the full stack. See the development phases guide for extending functionality following the MCP server patterns with FastAPI endpoints, SQLAlchemy ORM, and client-server coordination.

### ðŸ“Š Architecture Documentation

Comprehensive system diagrams available in `./diagrams/`:
- **architecture.md** - Complete system architecture with components and data flow
- **data-flow.md** - Detailed request/response flow through the system
- **distributed-state.md** - Multi-device coordination and state management
- **task-dependencies.md** - Task dependency resolution and execution phases

## Implementation Phases

### Phase 0: Server Infrastructure and Configuration Contract âœ… COMPLETED
**Objective:** Create the service backbone, establish the ORM for PostgreSQL, and define the configuration contract for external clients.

- âœ… **Configuration Contract**: `mcp_client_config.json` with `client_id`, `server_url`, `auth_token`, and `polling_interval_sec`
- âœ… **Database & ORM**: Implemented `db.py` with PostgreSQL async support and `orm.py` with SQLAlchemy models
- âœ… **Core API Endpoints**: `POST /v1/tasks` and `POST /v1/results` with Pydantic validation and Bearer token auth
- âœ… **Dependencies**: FastAPI, uvicorn, async SQLAlchemy, PostgreSQL, OpenAI, Docker deployment ready

**Go/No-Go Checkpoints:**
- âœ… `mcp_client_config` schema loads successfully in production containers
- âœ… ORM test persists and retrieves full `TaskGraph` structure to PostgreSQL
- âœ… API endpoints live with proper Pydantic validation and Bearer token auth

### Phase 1: Data Contracts and API Definitions âœ… COMPLETED
**Objective:** Finalize all Pydantic schemas and define core communication endpoints for external Workers.

- âœ… **Pydantic Schemas**: Complete `models.py` with `TaskGraph`, `ThoughtAction`, `Result`, `AuditReport`
- âœ… **Task Submission**: `POST /v1/tasks` endpoint with `TaskGraphRequest` validation
- âœ… **Task Polling**: `GET /v1/tasks/ready` with `agent_id` query parameter and Bearer token validation
- âœ… **Result Reporting**: `POST /v1/results` endpoint receiving structured `Result` from Workers

**Go/No-Go Checkpoints:**
- âœ… All API endpoints accept required Pydantic data structures
- âœ… Bearer token validation working across all endpoints
- âœ… Task polling returns oldest `READY` task for specified agent with atomic claiming

### Phase 2: Agent Core Logic (RA & Decoupling)
**Objective:** Implement core Agent intelligence (RA) logic, decoupled from API layer, with finalized system prompts.

- **Worker RA Implementation**: `execute_task` logic with internal loop generating structured `ThoughtAction` output
- **File Safety Integration**: WorkerAgent with file lock coordination, path extraction, and conflict prevention
- **Auditor Logic**: `run_audit` with critical system prompt returning `AuditReport` with actionable rework suggestions
- **LLM Client**: Strict Pydantic output enforcement for both Worker RA steps and Auditor reports
- **System Prompts**: Detailed prompts emphasizing RA pattern and specific agent roles

**Go/No-Go Checkpoints:**
- âœ… Worker test run generates complete RA history in structured `Result`
- âœ… File access coordination prevents concurrent worker conflicts
- âœ… Auditor flags known "bad" input and returns concrete `rework_suggestions`
- âœ… LLM calls reliably return structured Python objects, not raw text

### Phase 3: Manager Orchestration and Control (Scheduling)
**Objective:** Implement central MCP logic: scheduling, dependency management, and full audit loop.

- **Database-Driven Planning**: `plan_and_save_task` persists `TaskGraph` and marks initial tasks as `READY`
- **Dependency Scheduling**: `check_and_dispatch_ready_tasks` with atomic status updates based on dependencies
- **File Lock Management**: Database-tracked file access coordination with FileAccessORM and cleanup operations
- **Audit Control Loop**: Handle `POST /v1/results` endpoint, update DB, check completion, initiate audit
- **Rework Coordination**: Failed audits update DB with rework notes and reset tasks to `PENDING`

**Go/No-Go Checkpoints:**
- âœ… Task submission results in persisted `TaskGraph` with initial tasks marked `READY`
- âœ… Completed task correctly updates dependent task statuses to `READY`
- âœ… File locking prevents concurrent access conflicts across multiple workers
- âœ… Final result triggers audit; failed audit updates DB and resets tasks for rework

### Phase 4: Client Simulation and Production Readiness
**Objective:** Create external Worker Client, prove decoupled system works, validate resilience.

- **Worker Client**: `client_worker.py` with polling loop using `httpx`, adhering to `mcp_client_config.json`
- **File Safety Testing**: Multi-worker file access validation with concurrent conflict prevention
- **Concurrency Validation**: Multiple client instances with atomic status updates preventing task duplication
- **Full Resilience Test**: End-to-end test with parallel tasks, dependencies, and forced audit failure
- **Integration Testing**: Complete workflow from client polling to server rework update

**Go/No-Go Checkpoints:**
- âœ… Client script connects, polls, executes, and posts results to server API
- âœ… File access coordination prevents concurrent worker conflicts in multi-client scenarios
- âœ… Concurrency validated: no duplicate task execution, reliable status transitions
- âœ… System demonstrates full **Parallel â†’ Audit â†’ Rework â†’ Synthesis** cycle